{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "#import dataset\n",
    "location = \"../Final_dataset/\"\n",
    "\n",
    "test = datasets.load_dataset(\"csv\", data_files=location + \"test_atomic.tsv\", delimiter=\"\\t\")\n",
    "test = test.rename_column(\"label\", \"labels\")\n",
    "test = test['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(\n",
    "\tapi_key = key,\n",
    ")\n",
    "\n",
    "def get_response(example):\n",
    "\tpremise = example['premise']\t\n",
    "\thypothesis = example['hypothesis']\n",
    "\tuser_message = \"PREMISE: \" + premise + \"\\nHYPOTHESIS: \" + hypothesis + \"\\n\\n\"\n",
    "\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t  model=\"gpt-3.5-turbo-0125\",\n",
    "\t  messages=[\n",
    "\t\t{\"role\": \"system\", \"content\": \"Answer if the folowing pair of premise and hypothesis are (contradiction, neutral, entailment) return only the label.\"},\n",
    "\t\t{\"role\": \"user\", \"content\": user_message}\n",
    "\t  ]\n",
    "\t)\n",
    "\treturn response\n",
    "\n",
    "#go through the test set and get the responses\n",
    "responses = []\n",
    "\n",
    "correct = ['contradiction', 'neutral', 'entailment']\n",
    "for example in test:\n",
    "\tresponse = get_response(example)\n",
    "\t\"\"\" print(response.choices[0].message.content)\n",
    "\tbreak \"\"\"\n",
    "\tchoices = response.choices\n",
    "\t\"\"\" for i in range(len(choices)):\n",
    "\t\t#if it is in correct\n",
    "\t\tmessage = choices[i].message.content.lower()\n",
    "\t\tif message is not None and message in correct:\n",
    "\t\t\tprint(i)\n",
    "\t\t\tresponses.append(message)\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tprint(\"not found\") \"\"\"\n",
    "\t#go trhough the choices and get the first one that is in correct else put in -1\n",
    "\tfound = False\n",
    "\n",
    "\tfor i in range(len(choices)):\n",
    "\t\tmessage = choices[i].message.content.lower()\n",
    "\t\tif message is not None and message in correct:\n",
    "\t\t\tresponses.append(message)\n",
    "\t\t\tfound = True\n",
    "\t\t\tbreak\n",
    "\tif not found:\n",
    "\t\tresponses.append(\"-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n",
      "547\n",
      "0.5155393053016454\n"
     ]
    }
   ],
   "source": [
    "#calculate the accuracy\n",
    "correct = 0\n",
    "print(len(test))\n",
    "print(len(responses))\n",
    "for i in range(len(test)):\n",
    "\tif responses[i] == test[i]['labels']:\n",
    "\t\tcorrect += 1\n",
    "\n",
    "accuracy = correct / len(responses)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATOMIC\n",
    "\n",
    "def get_response_atomic(example):\n",
    "\tpremise = example['premise']\t\n",
    "\thypothesis = example['hypothesis']\n",
    "\tpremise_atomic = example['premise_atomic']\n",
    "\thypothesis_atomic = example['hypothesis_atomic']\n",
    "\n",
    "\tuser_message = \"PREMISE: \" + premise + \"\\nDESCRIPTION: \" + premise_atomic + \"\\nHYPOTHESIS: \" + hypothesis + \"\\nDESCRIPTION: \" + hypothesis_atomic + \"\\n\\n\"\n",
    "\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t  model=\"gpt-3.5-turbo-0125\",\n",
    "\t  messages=[\n",
    "\t\t{\"role\": \"system\", \"content\": \"Answer if the folowing pair of premise and hypothesis are (contradiction, neutral, entailment) return only the label.\"},\n",
    "\t\t{\"role\": \"user\", \"content\": user_message}\n",
    "\t  ]\n",
    "\t)\n",
    "\n",
    "#go through the test set and get the responses\n",
    "responses = []\n",
    "\n",
    "correct = ['contradiction', 'neutral', 'entailment']\n",
    "for example in test:\n",
    "\tresponse = get_response(example)\n",
    "\t\"\"\" print(response.choices[0].message.content)\n",
    "\tbreak \"\"\"\n",
    "\tchoices = response.choices\n",
    "\t\"\"\" for i in range(len(choices)):\n",
    "\t\t#if it is in correct\n",
    "\t\tmessage = choices[i].message.content.lower()\n",
    "\t\tif message is not None and message in correct:\n",
    "\t\t\tprint(i)\n",
    "\t\t\tresponses.append(message)\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tprint(\"not found\") \"\"\"\n",
    "\t#go trhough the choices and get the first one that is in correct else put in -1\n",
    "\tfound = False\n",
    "\n",
    "\tfor i in range(len(choices)):\n",
    "\t\tmessage = choices[i].message.content.lower()\n",
    "\t\tif message is not None and message in correct:\n",
    "\t\t\tresponses.append(message)\n",
    "\t\t\tfound = True\n",
    "\t\t\tbreak\n",
    "\tif not found:\n",
    "\t\tresponses.append(\"-1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
